{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "DATA_PATH is set to: \\\\10.34.1.59\\big_gulp\\nc4_rat_data\\Maze_Rats\n",
      "Using path: \\\\10.34.1.59\\big_gulp\\nc4_rat_data\\Maze_Rats\n",
      "Using path: \\\\10.34.1.59\\big_gulp\\nc4_rat_data\\Maze_Rats\n",
      "Looking in folder: \\\\10.34.1.59\\big_gulp\\nc4_rat_data\\Maze_Rats\\NC40008\n",
      "Looking in folder: \\\\10.34.1.59\\big_gulp\\nc4_rat_data\\Maze_Rats\\NC40008\\241108\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "Error processing: Chamber 5 selected - list index out of range\n",
      "DataFrame saved to \\\\10.34.1.59\\big_gulp\\nc4_rat_data\\Maze_Rats\\NC40008\\241108\\extracted_biases.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afsoo\\AppData\\Local\\Temp\\ipykernel_65040\\1170023984.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['Trial Type'] = new_df.apply(determine_trial_type, axis=1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 3 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m new_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrial Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39munstack(fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Rename columns for clarity\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[43mgrouped_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError_Count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuccess_Count\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Calculate total repetitions of each trial type\u001b[39;00m\n\u001b[0;32m     69\u001b[0m grouped_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Repetitions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grouped_df\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\afsoo\\anaconda3\\envs\\mazeenv\\lib\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\afsoo\\anaconda3\\envs\\mazeenv\\lib\\site-packages\\pandas\\core\\generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\afsoo\\anaconda3\\envs\\mazeenv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\afsoo\\anaconda3\\envs\\mazeenv\\lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 3 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "import bagpy\n",
    "from bagpy import bagreader\n",
    "import os\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse as parsedate\n",
    "import matplotlib.pyplot as plt\n",
    "from rosbags.highlevel import AnyReader as RosBagReader\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from dotenv import dotenv_values\n",
    "from dotenv import load_dotenv\n",
    "import ast \n",
    "import math\n",
    "from functions import *\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency, chi2\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config = dotenv_values()\n",
    "data_path = os.path.normpath(config['DATA_PATH'])\n",
    "os.environ['DATA_PATH'] = data_path\n",
    "print(f\"DATA_PATH is set to: {os.environ['DATA_PATH']}\")\n",
    "\n",
    "rat_number = 8\n",
    "date = '241108'\n",
    "\n",
    "messages, bag_file = determine_trial_info(rat_number, date)\n",
    "\n",
    "extracted_biases_file_path = os.path.join(os.path.dirname(bag_file), 'extracted_biases.csv')\n",
    "\n",
    "#check whether the files aleady exist. If they exist read them if not create them.\n",
    "if os.path.exists(extracted_biases_file_path):\n",
    "    #read the extracted bias csv file that contains trial information\n",
    "    extracted_biases = pd.read_csv(extracted_biases_file_path)\n",
    "    #read the trial type summary csv file\n",
    "    csv_trial_type_summary = os.path.join(os.path.dirname(bag_file), 'trial_type_summary.csv')\n",
    "    trial_type_summary = pd.read_csv(csv_trial_type_summary)\n",
    "    print('The dataframes have been created previously')\n",
    "else:\n",
    "    filtered_masseages = filter_start_of_trial_messages(messages)\n",
    "\n",
    "    final_messages = remove_specific_message(filtered_masseages)\n",
    "\n",
    "    print(final_messages)\n",
    "    df = create_dataframe_from_messages(final_messages)\n",
    "\n",
    "    #seperate the 'Left Cue', 'Right Cue', 'Sound Cue' of each Trial (row) and pu them in three new columns\n",
    "    df[['Left Cue', 'Right Cue', 'Floor Cue']] = df['Trial'].apply(lambda x: pd.Series(extract_trial_info(x)))\n",
    "\n",
    "    df['Start Chamber Number'] = df['Start Chamber'].str.extract(r'Chamber (\\d+)')\n",
    "\n",
    "    #change the order of the columns \n",
    "    new_df = df[['Number', 'Start Chamber Number', 'Left Cue', 'Right Cue', 'Floor Cue', 'Result', 'Choice']]\n",
    "\n",
    "    new_df['Trial Type'] = new_df.apply(determine_trial_type, axis=1)\n",
    "\n",
    "    new_df.to_csv(extracted_biases_file_path, index=False)\n",
    "\n",
    "    print(f\"DataFrame saved to {extracted_biases_file_path}\")\n",
    "\n",
    "    # Group by 'Trial Types' and 'Results' and count occurrences\n",
    "    grouped_df = new_df.groupby(['Trial Type', 'Result']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    grouped_df.columns = ['Error_Count', 'Success_Count']\n",
    "\n",
    "    # Calculate total repetitions of each trial type\n",
    "    grouped_df['Total_Repetitions'] = grouped_df.sum(axis=1)\n",
    "\n",
    "    # Reset index to make 'Trial Types' a column again\n",
    "    grouped_df = grouped_df.reset_index()\n",
    "\n",
    "     #Create a DataFrame with all 4 trial types and zeros for counts\n",
    "    all_trial_types = pd.DataFrame({\n",
    "        'Trial Type': range(1, 5)\n",
    "    })\n",
    "\n",
    "    # Merge the all_trial_types DataFrame with grouped_df\n",
    "    # Use a left join to ensure all trial types are included\n",
    "    final_df = pd.merge(all_trial_types, grouped_df, on='Trial Type', how='left')\n",
    "\n",
    "    # Fill NaN values resulting from the merge with 0\n",
    "    final_df = final_df.fillna(0)\n",
    "\n",
    "    # Ensure all counts are integers\n",
    "    final_df['Error_Count'] = final_df['Error_Count'].astype(int)\n",
    "    final_df['Success_Count'] = final_df['Success_Count'].astype(int)\n",
    "    final_df['Total_Repetitions'] = final_df['Total_Repetitions'].astype(int)\n",
    "\n",
    "    # Save the aggregated data to a new CSV file\n",
    "    output_csv_path = os.path.join(os.path.dirname(bag_file), 'trial_type_summary.csv')\n",
    "    grouped_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Summary saved to {output_csv_path}\")\n",
    "\n",
    "\n",
    "past_three_days_file_path = os.path.join(os.path.dirname(bag_file), 'Past_three_days_biases.csv')\n",
    "overall_success_path = os.path.join(os.path.dirname(bag_file), 'Overall_Success.csv')\n",
    "#check whether the analysis csv files of the past three days aleady exists. If it exists read it if not create it.\n",
    "if os.path.exists(past_three_days_file_path):\n",
    "    #read the extracted bias csv file that contains trial information\n",
    "    past_three_days_biases = pd.read_csv(past_three_days_file_path)\n",
    "    overall_success = pd.read_csv(overall_success_path)\n",
    "    print('The dataframes have been created previously')\n",
    "else:\n",
    "    combine_csv_files(rat_number, date)\n",
    "    past_three_days_biases = pd.read_csv(past_three_days_file_path)\n",
    "    overall_success = pd.read_csv(overall_success_path)\n",
    "\n",
    "save_plots_dir = os.path.join(os.path.dirname(bag_file), 'plots')\n",
    "\n",
    "#check whether the plots have been created before. If not, create them.\n",
    "if os.path.exists(save_plots_dir):\n",
    "    print('The plots have been created previously')\n",
    "else:\n",
    "    csv_trial_type_summary = os.path.join(os.path.dirname(bag_file), 'trial_type_summary.csv')\n",
    "    trial_type_summary = pd.read_csv(csv_trial_type_summary)\n",
    "    trial_type_summary['Success_Rate'] = trial_type_summary['Success_Count'] / trial_type_summary['Total_Repetitions']\n",
    "    \n",
    "    # Create the 'plots' directory if it doesn't exist\n",
    "    os.makedirs(save_plots_dir, exist_ok=True)\n",
    "\n",
    "    # Plot success rate for each trial type\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Trial Type', y='Success_Rate', data=trial_type_summary)\n",
    "    plt.title('Success Rate per Trial Type (Daily)')\n",
    "    plt.xlabel('Trial Type')\n",
    "    plt.ylabel('Success Rate')\n",
    "\n",
    "    # Define the file name and full path\n",
    "    file_name1 = 'Success Rate per Trial Type (Daily).png'\n",
    "    save_path1 = os.path.join(save_plots_dir, file_name1)\n",
    "\n",
    "    # Save the plot to the defined path\n",
    "    plt.savefig(save_path1)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Trial Type', y='Success_Count', data= past_three_days_biases)\n",
    "    plt.title('Success Rate per Trial Type (7-Day Cumulative)')\n",
    "    plt.xlabel('Trial Type')\n",
    "    plt.ylabel('Success Rate')\n",
    "\n",
    "    # Define the file name and full path\n",
    "    file_name2 = 'Success Rate per Trial Type (7-Day Cumulative).png'\n",
    "    save_path2 = os.path.join(save_plots_dir, file_name2)\n",
    "\n",
    "    # Save the plot to the defined path\n",
    "    plt.savefig(save_path2)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot total repetitions to see if the rat prefers certain trial types\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Trial Type', y='Total_Repetitions', data=trial_type_summary)\n",
    "    plt.title('Total Repetitions per Trial Type (Daily)')\n",
    "    plt.xlabel('Trial Type')\n",
    "    plt.ylabel('Total Repetitions')\n",
    "\n",
    "    # Define the file name and full path\n",
    "    file_name3 = 'Total Repetitions per Trial Type (Daily).png'\n",
    "    save_path3 = os.path.join(save_plots_dir, file_name3)\n",
    "\n",
    "    # Save the plot to the defined path\n",
    "    plt.savefig(save_path3)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Trial Type', y='Total_Repetitions', data=past_three_days_biases)\n",
    "    plt.title('Total Repetitions per Trial Type (7-Day Cumulative)')\n",
    "    plt.xlabel('Trial Type')\n",
    "    plt.ylabel('Total Repetitions')\n",
    "\n",
    "    #Define the file name and full path\n",
    "    file_name4 = 'Total Repetitions per Trial Type (3-Days Cumulative).png'\n",
    "    save_path4 = os.path.join(save_plots_dir, file_name4)\n",
    "\n",
    "    # Save the plot to the defined path\n",
    "    plt.savefig(save_path4)\n",
    "    plt.show()\n",
    "\n",
    "    melted_df = overall_success.melt(value_vars=['Overall_Success_Day_1', 'Overall_Success_Day_2', 'Overall_Success_Day_3'],\n",
    "                    var_name='Day', value_name='Overall_Success')\n",
    "\n",
    "    # Rename days for better x-axis labeling\n",
    "    melted_df['Day'] = melted_df['Day'].str.replace('Overall_Success_Day_', 'Day ')\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x='Day', y='Overall_Success', data=melted_df, marker='o', color='b')\n",
    "    plt.title('Overall Success Over the Last Three Days')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Overall Success')\n",
    "    plt.ylim(0, 1)  # Adjust y-axis if needed based on the range of success values\n",
    "\n",
    "    file_name5 = 'Overall_Success_Last_Three_Days.png'\n",
    "    save_path5 = os.path.join(save_plots_dir, file_name5)\n",
    "\n",
    "    # Save the plot to the defined path\n",
    "    plt.savefig(save_path5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a contingency table for correct vs. wrong counts across all trial types\n",
    "contingency_table = past_three_days_biases[['Success_Count', 'Error_Count']].values\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-square Statistic: {chi2_stat}\")\n",
    "print(f\"P-Value: {p_val}\")\n",
    "\n",
    "# Interpret the result\n",
    "if p_val < 0.05:\n",
    "    print(\"There is a statistically significant difference in performance across trial types.\")\n",
    "else:\n",
    "    print(\"No statistically significant difference found across trial types.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                  \n",
    "\n",
    "   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mazeenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
